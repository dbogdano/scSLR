{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85b6b692-9dd2-4cde-8a1c-8b74a5bd54a6",
   "metadata": {},
   "source": [
    "# GIA - Generation of NULL sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78bdc1b1-f8e7-437d-b6f2-0a647f693be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Oct  9 13:15:51 PDT 2024\n",
      "c4-gpudev1\n"
     ]
    }
   ],
   "source": [
    "!date\n",
    "!hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98f9ba31-388a-4f65-8793-9fd896c30b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/c4/home/derek/miniconda3/envs/deepripe'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env CONDA_PREFIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71706db6-6fd6-402d-9954-5d8f1630948f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2367534b-43c3-4bc3-ae5b-a3f8630fec9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 13:16:09.084071: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-09 13:16:09.435699: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "import pysam \n",
    "import tensorflow as tf\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#import modified basenji modules \n",
    "import sys\n",
    "sys.path.append(\"/nowakowskilab/data1/derek/data_scSLR/prenatal_brain/deep_splicing\")\n",
    "\n",
    "from basenji_.basenji.dna_io import dna_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74421f73-7121-49d4-bd77-31316bced9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modified basenji modules \n",
    "sys.path.append(\"/nowakowskilab/data1/derek/data_scSLR/prenatal_brain/deep_splicing\")\n",
    "from basenji_.basenji.dna_io import dna_1hot\n",
    "\n",
    "def region_to_mat(region):\n",
    "    region_len = len(region)\n",
    "    region= region.replace('i','0')\n",
    "    region= region.replace('c','1')\n",
    "    region= region.replace('3','2')\n",
    "    region= region.replace('5','3')\n",
    "    region= region.replace('N','4')\n",
    "    region_code = np.zeros((4,region_len), dtype='float16')\n",
    "    for i in range(region_len):\n",
    "        if int(region[i]) != 4:\n",
    "            region_code[int(region[i]),i] = 1\n",
    "        else:\n",
    "            region_code[0:4,i] = np.tile(0,4)\n",
    "    return np.transpose(region_code).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcf1dc33-420e-4314-9f3f-96a7aedd5437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nowakowskilab/data1/derek/data_scSLR/prenatal_brain/deep_splicing/transfer_learning'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168ac5a2-9bf5-429d-b0a2-ab156a4610cc",
   "metadata": {},
   "source": [
    "## Load MAJIQ cassette exon annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ec15801-47f7-44e2-ab8a-f3bd527cccbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/derek/ipykernel_3726499/3976852381.py:3: DtypeWarning: Columns (15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cass = pd.read_csv(input_dir+'cassette.tsv',sep='\\t',comment='#')\n"
     ]
    }
   ],
   "source": [
    "input_dir ='/c4/home/derek/data1//derek/data_scSLR/prenatal_brain/majiq/voila_modulize_out_PSI_0.01_wConstitutive/'\n",
    "\n",
    "cass = pd.read_csv(input_dir+'cassette.tsv',sep='\\t',comment='#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4398425c-1b45-43ca-be6c-5719ed5db9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aac4787-511c-432e-884f-f343eb8e94cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ed25944-f18b-4a86-a8a4-c1042ac7320e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['module_id', 'gene_id', 'gene_name', 'seqid', 'strand', 'lsv_id',\n",
       "       'event_id', 'complex', 'denovo', 'reference_exon_coord', 'spliced_with',\n",
       "       'spliced_with_coord', 'junction_name', 'junction_coord', 'event_size',\n",
       "       'event_non_changing', 'event_changing', 'junction_changing',\n",
       "       'merged_complete_median_reads', 'merged_complete_median_psi',\n",
       "       'merged_complete_var_psi'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cass.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7253327-fe2f-4cc3-9f4b-c5d8e7a36872",
   "metadata": {},
   "outputs": [],
   "source": [
    "cass = cass.drop(['module_id', 'gene_name','lsv_id','event_id','complex',\n",
    "      'denovo','reference_exon_coord', 'junction_name', 'junction_coord',\n",
    "        'event_non_changing','event_changing','junction_changing'\n",
    "          ], axis=1 )\n",
    "\n",
    "cass = cass[cass.spliced_with == 'A']\n",
    "cass = cass.drop_duplicates(subset = 'spliced_with_coord')\n",
    "\n",
    "cass[['start','end']] = cass.spliced_with_coord.str.split('-',expand=True)\n",
    "\n",
    "cass = cass[cass['end'].astype(int) > cass['start'].astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6367bdb6-bd0c-415c-9d42-5d67e37cd934",
   "metadata": {},
   "outputs": [],
   "source": [
    "cass['model_input'] = cass['seqid']+'_'+cass['start']+'_'+cass['end']+'_'+cass['gene_id'].str[:-3]+'_'+cass['strand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc23d61c-b98e-4cb4-8870-0745c2ebd4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c91d342-bc6a-48e2-8940-9854a6eb84e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = '/nowakowskilab/data1/derek/data_scSLR/prenatal_brain/deep_splicing/transfer_learning/'\n",
    "\n",
    "null_orig = pd.read_csv(in_dir+'sig_dif_NULL_table.csv', index_col=0)\n",
    "EN = pd.read_csv(in_dir+'sig_dif_EN_table_0.1_.csv', index_col=0)\n",
    "RG = pd.read_csv(in_dir+'sig_dif_RG_table_0.1_.csv', index_col=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2b379ad-46c7-4a3f-962f-236d5d63f566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove exons included in the differentially spliced in EN, RG sets\n",
    "\n",
    "cass = cass[~cass.model_input.isin(pd.concat([RG.model_input,\n",
    "                                 EN.model_input,\n",
    "                                 null_orig.model_input]\n",
    "                               )\n",
    "                     )\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4484dc3-1002-497f-9af5-caf691d53ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96dcefdd-90eb-49f9-a521-6807470a5bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_data = pd.DataFrame(cass.model_input).set_index('model_input')\n",
    "\n",
    "null_data[0] = 0\n",
    "null_data.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f3905f8-098b-4f20-bb8b-7ccb0ff6e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_data = null_data.sample(n = 2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a82fa4a-6419-497f-8f0d-02df40e214e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NULL = null_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f97ece8-95b3-4248-9232-724c84afef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "NULL = NULL.loc[NULL.index.drop_duplicates()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cf9d2cb-a927-4abf-8f5e-18d13b30edaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chr9_10612398_10612453_ENSG00000153707_-</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr19_7630754_7630846_ENSG00000229833_+</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr4_98909678_98909959_ENSG00000151247_-</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr15_82418639_82418792_ENSG0000029094_+</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1_227254064_227254155_ENSG00000143776_-</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr14_96593490_96593579_ENSG0000025870_+</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr3_10125626_10125708_ENSG0000025499_+</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr2_8958497_8958642_ENSG00000143797_-</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr10_46794727_46794915_ENSG0000029106_+</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr19_36473332_36473458_ENSG00000186017_-</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            0\n",
       "chr9_10612398_10612453_ENSG00000153707_-    0\n",
       "chr19_7630754_7630846_ENSG00000229833_+     0\n",
       "chr4_98909678_98909959_ENSG00000151247_-    0\n",
       "chr15_82418639_82418792_ENSG0000029094_+    0\n",
       "chr1_227254064_227254155_ENSG00000143776_-  0\n",
       "...                                        ..\n",
       "chr14_96593490_96593579_ENSG0000025870_+    0\n",
       "chr3_10125626_10125708_ENSG0000025499_+     0\n",
       "chr2_8958497_8958642_ENSG00000143797_-      0\n",
       "chr10_46794727_46794915_ENSG0000029106_+    0\n",
       "chr19_36473332_36473458_ENSG00000186017_-   0\n",
       "\n",
       "[2500 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58d1725f-c1ae-45d6-8f89-ee33aa073064",
   "metadata": {},
   "outputs": [],
   "source": [
    "exon_info = pd.DataFrame(NULL.index)[0].str.split('_', expand=True)\n",
    "exon_info = exon_info.rename(columns={0: 'chr', 1: 'start', 2: 'end',\n",
    "                                      3: 'ENSG', 4: 'strand'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a581cf-991c-44b6-9611-b4dc9895a756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcc1fab2-79c8-44a0-8750-d0ae3968fb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce null exons to those being > 100bp\n",
    "\n",
    "# exon_info = exon_info[np.abs(exon_info['start'].astype(int) - exon_info['end'].astype(int) ) > 100][:1000]\n",
    "\n",
    "# NULL = NULL.iloc[exon_info.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64482d2-84d0-4d9c-acbf-a0ce3712d7de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abcfe17-fdd3-41a4-9e93-30fec2e67af1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2bdc90dd-4b5f-4e02-9987-29b80ce2d487",
   "metadata": {},
   "outputs": [],
   "source": [
    "intron_flanking_length = 150\n",
    "# exon_flanking_length = 50\n",
    "\n",
    "\n",
    "exon_info['start'] = exon_info['start'].astype(int) - intron_flanking_length\n",
    "exon_info['end'] = exon_info['end'].astype(int) + intron_flanking_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a5c919f-6ac5-475a-9ff6-04dff2ebb9f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NULL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "72c5f602-3a87-4548-9889-cca22e7df6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NULL = NULL.iloc[exon_info.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "37726371-2691-4343-a8e0-6e69d88166b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "exon_info_set = exon_info.copy()\n",
    "\n",
    "num_targets = 2\n",
    "max_length = 600\n",
    "region_length = 1000\n",
    "num_layers=5\n",
    "\n",
    "extra = int((region_length - max_length)/8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a82e2eb-119f-45b3-910e-e51d94eceaac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d3bfe130-62ad-4ec8-916f-b2f2b0b7e070",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "                    # define ranges for all regions of interest and pad if shorter than intron_flanking_length\n",
    "                    \n",
    "\n",
    "\n",
    "                    # # upstream_intron \n",
    "                    \n",
    "                    # upstream_intron = seq_DNA[0:intron_flanking_length]\n",
    "                    \n",
    "                    # upstream_intron_region = ('i'*extra)+('i'*intron_flanking_length)+('c'*extra)\n",
    "                    \n",
    "                    # #exon_start\n",
    "                    \n",
    "                    # exon_coord = len(seq_DNA) // 2\n",
    "                    \n",
    "                    # if exon_coord <= (exon_flanking_length * 2):\n",
    "                    \n",
    "                    #     exon_start = seq_DNA[intron_flanking_length:exon_coord]\n",
    "                    \n",
    "                    #     padding_start = exon_flanking_length - len(exon_start)\n",
    "\n",
    "                    #     exon_start = exon_start + padding_start*'N'\n",
    "\n",
    "                        \n",
    "                    # else: \n",
    "                        \n",
    "                    #     exon_start =  seq_DNA[intron_flanking_length:(intron_flanking_length + exon_flanking_length)]\n",
    "\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    # exon_start_region = ('i'*extra)+''.join(['c' if x != 'N' else 'N' for x in exon_start])+('N'*extra)\n",
    "                    \n",
    "                    # # downstream_intron\n",
    "                    \n",
    "                    # downstream_intron = seq_DNA[(len_DNA-intron_flanking_length):len_DNA]\n",
    "                    \n",
    "                    # downstream_intron_region = ('c'*extra)+('i'*intron_flanking_length)+('i'*extra)\n",
    "\n",
    "                    # # exon_end\n",
    "                    \n",
    "                    # exon_coord = len(seq_DNA) // 2 \n",
    "                    \n",
    "                    # if exon_coord <= (exon_flanking_length * 2): \n",
    "                    \n",
    "                    #     exon_end = seq_DNA[exon_coord:(len_DNA-intron_flanking_length)]\n",
    "                        \n",
    "                    #     padding_end = exon_flanking_length - len(exon_end)\n",
    "\n",
    "                    #     exon_end = padding_end*'N' + exon_end\n",
    "\n",
    "        \n",
    "                        \n",
    "                    # else:\n",
    "                        \n",
    "                    #     exon_end = seq_DNA[(len_DNA-(intron_flanking_length + exon_flanking_length)):(len_DNA-intron_flanking_length)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    \n",
    "                    # upstream_intron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a08c9b-4e78-49f2-ae34-ae03c70ebbb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "61699bc7-a273-4175-a9f5-80b29225b619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "11c80087-71b7-48af-8a99-967378411c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = exon_info['ENSG']\n",
    "num_fold = 1\n",
    "file_folds = None\n",
    "peaks=0\n",
    "prefix='ALL_CASSETTE_PARCLIP_tfrecord'\n",
    "\n",
    "\n",
    "file_fasta = \"/c4/home/derek/data1/derek/reference/human_hg38_reference/refdata-gex-GRCh38-2020-A/fasta/genome.fa\"\n",
    "general_out_dir=f'./data_out/{prefix}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "94e4c687-3007-4e97-9d75-6c2126567f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfrecords_deepripe_null(PSI, exon_info, train_idxs, \n",
    "                  fold, general_out_dir, peaks,\n",
    "                     max_length, num_layers):\n",
    "    \n",
    "    fold_dir = general_out_dir + '/fold' + str(num_fold)\n",
    "    tfr_dir = fold_dir + '/tfrecords' \n",
    "    Path(fold_dir).mkdir(parents=True, exist_ok=True)\n",
    "    Path(tfr_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    fold_indexes = [train_idxs]\n",
    "    \n",
    "    # Write the file genes.csv\n",
    "    split = np.zeros((len(exon_info),1), dtype='<U5')\n",
    "    split[train_idxs] = 'train'\n",
    "    target = PSI.values\n",
    "    genes = pd.DataFrame(np.hstack((split,target)), \n",
    "                         index=PSI.index, columns=np.hstack((['split'], PSI.columns)))\n",
    "    \n",
    "    genes = genes[genes['split'] != '']\n",
    "    genes.to_csv(fold_dir + '/genes.csv')\n",
    "    \n",
    "    # Options TFR writer\n",
    "    tf_opts = tf.io.TFRecordOptions(compression_type='ZLIB')\n",
    "    seqs_per_tfr = 256\n",
    "    fold_labels = ['train']\n",
    "\n",
    "    \n",
    "    # open FASTA\n",
    "    fasta_open = pysam.Fastafile(file_fasta)\n",
    "    \n",
    "    def rc(seq):\n",
    "        return seq.translate(str.maketrans(\"ATCGatcg\",\"TAGCtagc\"))[::-1]\n",
    "    \n",
    "    def _bytes_feature(value):\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "    \n",
    "    # Write the TFRecords\n",
    "    num_folds = 1 #train-val-test\n",
    "    \n",
    "    for fi in range(num_folds):\n",
    "        exon_ID_set = PSI.index[fold_indexes[fi]]\n",
    "        exon_info_set = exon_info.iloc[fold_indexes[fi]]\n",
    "        PSI_val_set = PSI.iloc[fold_indexes[fi]]\n",
    "        \n",
    "        num_set = exon_ID_set.shape[0]\n",
    "        \n",
    "        num_set_tfrs = int(np.ceil(num_set / seqs_per_tfr)) \n",
    "        # print(num_set_tfrs)\n",
    "        \n",
    "        # gene sequence index\n",
    "        si = 0\n",
    "        \n",
    "        for tfr_i in range(num_set_tfrs):\n",
    "            # Create the file e.g 'tfr_records/test-0.tfr'\n",
    "            tfr_file = '%s/%s-%d.tfr' % (tfr_dir, fold_labels[fi], tfr_i)\n",
    "            # print(tfr_file)\n",
    "            with tf.io.TFRecordWriter(tfr_file, tf_opts) as writer:\n",
    "                # TFR index\n",
    "                ti = 0\n",
    "                \n",
    "                # This is to make sure that the max. genes per file stays below 256\n",
    "                # And that for the last batch we stop on time (si < num_set)\n",
    "                while ti < seqs_per_tfr and si < num_set:\n",
    "                    # Get the genes that should be in this set\n",
    "                    \n",
    "                    seq_chrm = exon_info_set['chr'].iloc[si]\n",
    "                    seq_start = int(exon_info_set['start'].iloc[si])\n",
    "                    seq_end = int(exon_info_set['end'].iloc[si])+1 #Because fasta.fetch doesn't include end bp\n",
    "                    seq_strand = exon_info_set['strand'].iloc[si]\n",
    "                    gene = exon_info_set['ENSG'].iloc[si]\n",
    "                    \n",
    "                    #start\n",
    "                    seq_start_ = seq_start\n",
    "                    #end\n",
    "                    seq_end_ = seq_end\n",
    "                    \n",
    "                    \n",
    "                    #get exon's range\n",
    "                    seq_DNA = fasta_open.fetch(seq_chrm, seq_start_, seq_end_)\n",
    "                    \n",
    "                    #and its length\n",
    "                    len_DNA = len(seq_DNA)\n",
    "                    \n",
    "                    # get positions of splice sites\n",
    "                    splicing_ind = np.array([intron_flanking_length, max_length - intron_flanking_length], dtype=np.int64)\n",
    "\n",
    "                    \n",
    "                    # orient\n",
    "                    if seq_strand == '-':\n",
    "                        seq_DNA = rc(seq_DNA)\n",
    "                        \n",
    "                                  \n",
    "                    upstream_intron = seq_DNA[0:intron_flanking_length]\n",
    "                    \n",
    "                    upstream_intron_region = ('i'*extra)+('i'*intron_flanking_length)+('c'*extra)\n",
    "                    \n",
    "                    #exon_start\n",
    "                    \n",
    "                    exon_coord = len(seq_DNA) // 2\n",
    "                    \n",
    "                    if exon_coord < (intron_flanking_length * 2):\n",
    "                    \n",
    "                        exon_start = seq_DNA[intron_flanking_length:exon_coord]\n",
    "                    \n",
    "                        padding_start = intron_flanking_length - len(exon_start)\n",
    "\n",
    "                        exon_start = exon_start + padding_start*'N'\n",
    "                        \n",
    "                    else: \n",
    "                        \n",
    "                        exon_start =  seq_DNA[intron_flanking_length:(intron_flanking_length * 2)]\n",
    "                    \n",
    "                    exon_start_region = ('i'*extra)+''.join(['c' if x != 'N' else 'N' for x in exon_start])+('N'*extra)\n",
    "                    \n",
    "                    # downstream_intron\n",
    "                    \n",
    "                    downstream_intron = seq_DNA[(len_DNA-intron_flanking_length):len_DNA]\n",
    "                    \n",
    "                    downstream_intron_region = ('c'*extra)+('i'*intron_flanking_length)+('i'*extra)\n",
    "\n",
    "                    # exon_end\n",
    "                    \n",
    "                    exon_coord = len(seq_DNA) // 2 \n",
    "                    \n",
    "                    if exon_coord < (intron_flanking_length * 2):\n",
    "                    \n",
    "                        exon_end = seq_DNA[exon_coord:(len_DNA-intron_flanking_length)]\n",
    "                        \n",
    "                        padding_end = intron_flanking_length - len(exon_end)\n",
    "                        \n",
    "                        exon_end = padding_end*'N' + exon_end\n",
    "                        \n",
    "                    else:\n",
    "                        \n",
    "                        exon_end = seq_DNA[(len_DNA-(intron_flanking_length * 2)):(len_DNA-intron_flanking_length)]\n",
    "\n",
    "                    \n",
    "                    exon_end_region = ('N'*extra)+''.join(['c' if x != 'N' else 'N' for x in exon_end])+('i'*extra)\n",
    "                        \n",
    "                        \n",
    "                    seq_DNA = (upstream_intron + exon_start + exon_end + downstream_intron)\n",
    "                      \n",
    "                    new_LEN = len(seq_DNA)\n",
    "                    if (new_LEN != max_length):\n",
    "                        print(exon_info_set.iloc[si])\n",
    "                        print(new_LEN)\n",
    "                        \n",
    "                    assert(new_LEN == max_length)\n",
    "                    \n",
    "                    seq_region = upstream_intron_region + exon_start_region + exon_end_region + downstream_intron_region\n",
    "                    assert(len(seq_region) == region_length)\n",
    "                \n",
    "                  \n",
    "                    \n",
    "                    # one hot code\n",
    "                    seq_1hot = dna_1hot(seq_DNA)\n",
    "                    seq_len = np.array(len(seq_DNA), dtype=np.int64)\n",
    "                    \n",
    "                    # splicing\n",
    "                    splicing = np.zeros((new_LEN ,1), dtype=np.int8)\n",
    "                    splicing[splicing_ind] = 1\n",
    "                    \n",
    "                    # region \n",
    "                    region_1hot = region_to_mat(seq_region)\n",
    "           \n",
    "                    # get targets\n",
    "                    targets = PSI_val_set.iloc[si].values\n",
    "                    targets = targets.reshape((1,-1)).astype('float64')\n",
    "                    \n",
    "            ### generate example ###\n",
    "                    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                           \n",
    "                            'length': _bytes_feature(seq_len.flatten().tobytes()),\n",
    "                            'sequence': _bytes_feature(seq_1hot.flatten().tobytes()),\n",
    "                            'target': _bytes_feature(targets.flatten().tobytes()),\n",
    "                            'splicing': _bytes_feature(splicing.flatten().tobytes()), \n",
    "                            'region': _bytes_feature(region_1hot.flatten().tobytes())\n",
    "                        }))\n",
    "    \n",
    "                    # write\n",
    "                    writer.write(example.SerializeToString())\n",
    "    \n",
    "                    # advance indexes\n",
    "                    ti += 1\n",
    "                    si += 1\n",
    "    \n",
    "    \n",
    "    fasta_open.close()\n",
    "    \n",
    "    \n",
    "    # Write statistics.json\n",
    "    \n",
    "    stats_dict = {}\n",
    "    stats_dict['num_targets'] = num_targets\n",
    "    stats_dict['seq_length'] = max_length\n",
    "    stats_dict['target_length'] = 4\n",
    "    \n",
    "    for fi in range(num_folds):\n",
    "        stats_dict['%s_seqs' % fold_labels[fi]] = len(fold_indexes[fi])\n",
    "    \n",
    "    with open('%s/statistics.json' % fold_dir, 'w') as stats_json_out:\n",
    "        json.dump(stats_dict, stats_json_out, indent=4)\n",
    "    \n",
    "    \n",
    "    # Copy the params.json\n",
    "    train_dict = {}\n",
    "    train_dict['batch_size'] = 64\n",
    "    train_dict['optimizer'] = 'adam'\n",
    "    train_dict['loss'] = 'bce' #'mse'\n",
    "    train_dict['learning_rate'] = 0.0001\n",
    "    train_dict['adam_beta1'] = 0.90\n",
    "    train_dict['adam_beta2'] = 0.998\n",
    "    train_dict['global_clipnorm'] = 0.5\n",
    "    train_dict['train_epochs_min'] = 100\n",
    "    train_dict['train_epochs_max'] = 1000\n",
    "    train_dict['patience'] = 100\n",
    "    \n",
    "    model_dict = {}\n",
    "    model_dict['activation'] = 'relu'\n",
    "    model_dict['spline'] = False\n",
    "    model_dict['rnn_type'] = 'gru'\n",
    "    model_dict['final_activation'] = 'relu'\n",
    "    model_dict['residual'] = False\n",
    "    model_dict['seq_length'] = max_length\n",
    "\n",
    "    model_dict['seq_depth'] = 4 \n",
    "    model_dict['augment_shift'] = 0\n",
    "    model_dict['num_targets'] = num_targets\n",
    "    model_dict['heads'] = 1\n",
    "    model_dict['filters'] = 186\n",
    "    model_dict['kernel_size'] = 6 #5\n",
    "    model_dict['dropout'] = 0.3 \n",
    "    model_dict['l2_scale'] = 0.001\n",
    "    model_dict['ln_epsilon'] = 0.007\n",
    "    model_dict['bn_momentum'] = 0.90\n",
    "    \n",
    "    params_dict = {}\n",
    "    params_dict['train'] = train_dict\n",
    "    params_dict['model'] = model_dict\n",
    "    \n",
    "    with open('%s/params.json' % fold_dir, 'w') as params_json_out:\n",
    "        json.dump(params_dict, params_json_out, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "de834488-4cd2-4f5b-8efa-566078b792b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data_out/ALL_CASSETTE_PARCLIP_tfrecord/'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_out_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b324f46-afa9-4b57-993c-d61dfde11621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5652e3f8-2b8b-49f8-811b-86bb7b3c03b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tfrecords_deepripe_null(NULL,\n",
    "                        exon_info, \n",
    "                        np.arange(0,len(NULL)),       \n",
    "                        num_fold, \n",
    "                       general_out_dir,\n",
    "                        peaks,\n",
    "                       max_length, \n",
    "                        num_layers\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7545ed-3aab-4cfa-a96c-0576eebd29a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e24291b-ed6c-4d14-8f2c-514d6f5af0bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce88590b-55fb-4942-acac-3aaf3222d951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171cc4c1-ccc2-4a49-9ac3-dd3441f069c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03895b9a-b42f-4c13-985f-5bfaa990e875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108b3a7c-89b2-4ae7-94e9-5c3061b3c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
